* Mac address spoofing

original: ether 82:97:3b:84:30:01

ifconfig en1 | grep ether
sudo ifconfig en1 ether 00:e2:e3:e4:e5:e6
openssl rand -hex 6 | sed 's/\(..\)/\1:/g; s/.$//'

* Notes on Amazon deployment

* cloudfront + nginx + docker + https + EB

We need https as future-proofing because Chrome is warning against http, but more urgently because Dropbox requires that the access token goes to a https endpoint.  This is the root of the problems in moving from laptop to cloud, as Dropbox permits http to localhost.  But https is tricky.

I had no problem sending /web via cloudfront behaviours to the diogenesweb container on EB with https connections before introducing nginx.  Apparently, cloudfront terminated the ssl and passed on the request to the container via http and port 80.

That changed when I added nginx.  Originally, it was listening on port ?? for https, so I think cloudfront passed the connection directly there.  But this requires telling nginx about my certificate and setting it up with the correct ssl_cipher setting (as this apparently causes issues with cloudfront.)  But I tried making nginx listen on just port 80, and that did not seem to fix the problem.  I think cloudfront was still passing the query via https.

https://stackoverflow.com/questions/20664018/cloudfront-custom-origin-distribution-returns-502-error-the-request-could-not-b

https://medium.com/faun/setting-up-ssl-certificates-for-nginx-in-docker-environ-e7eec5ebb418

* Notes
** https://forums.aws.amazon.com/thread.jspa?threadID=116853

>> I have set up a CloudFront distribution for a custom origin - one of our web sites which is publicly available.

If you're using an HTTP server as your origin, and if you want to use HTTPS both between viewers and CloudFront and between CloudFront and your origin, you must install an SSL certificate on the HTTP server that is signed by a third-party certificate authority, for example, VeriSign or DigiCert. That said I see that your cert looks to be signed by DigiCert so this should be correct.

Note If the origin server returns an invalid certificate or a self-signed certificate, or if the origin server returns the certificate chain in the wrong order, CloudFront drops the TCP connection, returns HTTP error code 503, and sets the X-Cache header to Error from cloudfront.

* Next steps
Install eb CLI via pip3
Create new EB environment
Install single docker running DW on port 80 and see if it can handle https
Install single docker with nginx and a test page on port 80 and test same
If not, try again by confgiuring nginx on port 443 with AWS cert.
See if it works on localhost, then try on AWS
Then try three containers on localhost, then on AWS

If all that doesn't work, try with EB 2-instance environment and load balancer.  Apparently, cloudfront may work better with this.

If that doesn't work, run dweb and dmorph in separate EB containers.

* Possibly useful
https://hackernoon.com/how-to-set-up-https-for-your-domain-on-aws-8f771686603d
https://serversforhackers.com/c/cloudfront-and-your-app
https://docs.aws.amazon.com/elasticbeanstalk/latest/dg/https-singleinstance-docker.html


* Separating out /web requests.
We use cloudfront behaviour rules for /web and /parse.  All others go to S3
https://serverfault.com/questions/891487/does-aws-offer-a-way-to-route-https-traffic-to-two-different-ec2-instances-based


* /web needs https
Dropbox insists on a https url, and it is tricky to switch back to plain http.  We connot mix the two, as localStorage is different for the two protocols.  So we use cloudfront to coerce to https

* CORS
Tricky to get S3 to serve XHR requests on both http and https
Need to configure the S3 storage to allow all hosts, but also do some trickery with Cloudfront to whitelist headers:
https://stackoverflow.com/questions/12358173/correct-s3-cloudfront-cors-configuration

* Docker
Three dockers with ngnix reverse proxy to allow both elements to sit in one container.
https://bobcares.com/blog/docker-multiple-containers-same-port/

* Deploy
Just push the Dockerrun.aws.json file
